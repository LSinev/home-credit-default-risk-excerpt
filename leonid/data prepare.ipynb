{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ca25a2f95f0fc9498b9b2e3a9d96607fbb682015"
   },
   "source": [
    "# Home Credit Default Risk 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "cc4088625ae2209899d05c70dfd7bcb108cb4c3a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "warnings.simplefilter(action = 'ignore', category = FutureWarning)\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except:\n",
    "    import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 2042\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../input/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.read_csv(f'{file_path}sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "be294207f4e12ccf54d922814789b27998577dca"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dask.distributed import Client\n",
    "\n",
    "# # If you have a remote cluster running Dask\n",
    "# # client = Client('tcp://scheduler-address:8786')\n",
    "\n",
    "# # If you want Dask to set itself up on your personal computer\n",
    "# client = Client(processes=False)\n",
    "\n",
    "# from joblib import parallel_backend, Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "962799c45d0c88ee9237cb0e202b11758abac536"
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "42960cc0257a40fee0876294c6956e0aeba23023"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ranksums\n",
    "from scipy.stats import gmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "0b5e7cfa7c94294ad8b1eab00438592d24450e11"
   },
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "USELESS_COLUMNS = ['FLAG_DOCUMENT_10',\n",
    "                   'FLAG_DOCUMENT_12',\n",
    "                   'FLAG_DOCUMENT_13',\n",
    "                   'FLAG_DOCUMENT_14',\n",
    "                   'FLAG_DOCUMENT_15',\n",
    "                   'FLAG_DOCUMENT_16',\n",
    "                   'FLAG_DOCUMENT_17',\n",
    "                   'FLAG_DOCUMENT_19',\n",
    "                   'FLAG_DOCUMENT_2',\n",
    "                   'FLAG_DOCUMENT_20',\n",
    "                   'FLAG_DOCUMENT_21']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "32f2b23ed9dabb4b8ec59cc86f1e9cecdc9abad3"
   },
   "source": [
    "## Aggregating datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3687d746e5fe89d3477cff12521e1402431c7ab1"
   },
   "source": [
    "### Service functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "4b1d9d1291ce3da6dc089ec6c3918f485528caf0"
   },
   "outputs": [],
   "source": [
    "def convert_col_to_proper_int(df_col):\n",
    "    col_type = df_col.dtype\n",
    "#     print('convert_col_to_proper_int column: ', df_col.name, 'type: ', col_type, 'c_min: ', c_min)\n",
    "    if ((str(col_type)[:3] == 'int') | (str(col_type)[:4] == 'uint')): # | (str(col_type)[:5] == 'float')\n",
    "        c_min = df_col.min()\n",
    "        c_max = df_col.max()\n",
    "        if c_min < 0:\n",
    "#             print('c_min: ', c_min, 'less 0')\n",
    "            if c_min >= np.iinfo(np.int8).min and c_max <= np.iinfo(np.int8).max:\n",
    "                df_col = df_col.astype(np.int8)\n",
    "            elif c_min >= np.iinfo(np.int16).min and c_max <= np.iinfo(np.int16).max:\n",
    "                df_col = df_col.astype(np.int16)\n",
    "            elif c_min >= np.iinfo(np.int32).min and c_max <= np.iinfo(np.int32).max:\n",
    "                df_col = df_col.astype(np.int32)\n",
    "            elif c_min >= np.iinfo(np.int64).min and c_max <= np.iinfo(np.int64).max:\n",
    "                df_col = df_col.astype(np.int64)\n",
    "        else:\n",
    "#             print('c_min: ', c_min, 'not less 0')\n",
    "            if c_max <= np.iinfo(np.uint8).max:\n",
    "                df_col = df_col.astype(np.uint8)\n",
    "            elif c_max <= np.iinfo(np.uint16).max:\n",
    "                df_col = df_col.astype(np.uint16)\n",
    "            elif c_max <= np.iinfo(np.uint32).max:\n",
    "                df_col = df_col.astype(np.uint32)\n",
    "            elif c_max <= np.iinfo(np.uint64).max:\n",
    "                df_col = df_col.astype(np.uint64)\n",
    "            \n",
    "    return df_col\n",
    "\n",
    "def convert_col_to_proper_float(df_col):\n",
    "    col_type = df_col.dtype\n",
    "    if str(col_type)[:5] == 'float':\n",
    "        unique_count = len(np.unique(df_col))\n",
    "        df_col_temp = df_col.astype(np.float32)\n",
    "        if len(np.unique(df_col_temp)) == unique_count:\n",
    "            df_col = df_col_temp\n",
    "            c_min = df_col.min()\n",
    "            c_max = df_col.max()\n",
    "            if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                df_col_temp = df_col.astype(np.float16)\n",
    "                if len(np.unique(df_col_temp)) == unique_count:\n",
    "                    df_col = df_col_temp\n",
    "            \n",
    "    return df_col\n",
    "\n",
    "\n",
    "\n",
    "def float_to_int(df):\n",
    "    \"\"\" iterate through all float columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.\n",
    "    \"\"\"\n",
    "#     print('Begin float_to_int')\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "#         print('column: ', col, 'type: ', col_type)\n",
    "        if str(col_type)[:5] == 'float':\n",
    "            if (df[col] % 1 == 0).all():\n",
    "                df[col] = convert_col_to_proper_int(df[col].astype(np.int64))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def float_reduced(df):\n",
    "    \"\"\" iterate through all float columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.\n",
    "    \"\"\"\n",
    "#     print('Begin float_reduced')\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "#         print('column: ', col, 'type: ', col_type)\n",
    "        if str(col_type)[:5] == 'float':\n",
    "            df[col] = convert_col_to_proper_float(df[col])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def int_reduced(df):\n",
    "    \"\"\" iterate through all int columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.\n",
    "    \"\"\"\n",
    "#     print('Begin float_reduced')\n",
    "    for col in df.columns:\n",
    "        df[col] = convert_col_to_proper_int(df[col])\n",
    "    \n",
    "    return df\n",
    "\n",
    "## Thanks You Guillaume Martin for the Awesome Memory Optimizer!\n",
    "## https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\n",
    "def reduce_mem_usage(data, verbose = True):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.\n",
    "    \"\"\"\n",
    "    start_mem = data.memory_usage().sum() / 1024**2\n",
    "    if verbose:\n",
    "        print('Memory usage of dataframe: {:.2f} MB'.format(start_mem))\n",
    "\n",
    "    for col in data.columns:\n",
    "#         print(col, type(data[col]), data[col].shape)\n",
    "        col_type = data[col].dtype\n",
    "\n",
    "        if ((col_type != object) & (col_type != '<M8[ns]') & (col_type.name != 'category')):#\n",
    "            c_min = data[col].min()\n",
    "            c_max = data[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                data[col] = convert_col_to_proper_int(data[col])\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    data[col] = data[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    data[col] = data[col].astype(np.float32)\n",
    "                else:\n",
    "                    data[col] = data[col].astype(np.float64)\n",
    "        else: data[col] = data[col].astype('category')\n",
    "\n",
    "    end_mem = data.memory_usage().sum() / 1024**2\n",
    "    if verbose:\n",
    "        print('Memory usage after optimization: {:.2f} MB'.format(end_mem))\n",
    "        print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "\n",
    "    return data\n",
    "\n",
    "def gentle_reduce_mem_usage(data, verbose = True):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.\n",
    "    \"\"\"\n",
    "    start_mem = data.memory_usage().sum() / 1024**2\n",
    "    if verbose:\n",
    "        print('Memory usage of dataframe: {:.2f} MB'.format(start_mem))\n",
    "\n",
    "    for col in data.columns:\n",
    "#         print(col, type(data[col]), data[col].shape)\n",
    "        col_type = data[col].dtype\n",
    "\n",
    "        if ((col_type != object) & (col_type != '<M8[ns]') & (col_type.name != 'category')):#\n",
    "            c_min = data[col].min()\n",
    "            c_max = data[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                data[col] = convert_col_to_proper_int(data[col])\n",
    "            else:\n",
    "                if (data[col] % 1 == 0).all():\n",
    "                    data[col] = convert_col_to_proper_int(data[col].astype(np.int64))\n",
    "                else:\n",
    "                    data[col] = convert_col_to_proper_float(data[col])\n",
    "        else: data[col] = data[col].astype('category')\n",
    "\n",
    "    end_mem = data.memory_usage().sum() / 1024**2\n",
    "    if verbose:\n",
    "        print('Memory usage after optimization: {:.2f} MB'.format(end_mem))\n",
    "        print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3cdf22861b989e1dfe6331ecef61b13ef3fa2d05"
   },
   "source": [
    "## Cleaning dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "c8536f211c9768b6f7622a43413e8bdd2a46092d"
   },
   "outputs": [],
   "source": [
    "def corr_feature_with_target(feature, target):\n",
    "    c0 = feature[target == 0].dropna()\n",
    "    c1 = feature[target == 1].dropna()\n",
    "        \n",
    "    if set(feature.unique()) == set([0, 1]):\n",
    "        diff = abs(np.mean(c0, axis=0) - np.mean(c1, axis=0))\n",
    "    else:\n",
    "        diff = abs(np.median(c0, axis=0) - np.median(c1, axis=0))\n",
    "        \n",
    "    p = ranksums(c0, c1)[1] if ((len(c0) >= 20) & (len(c1) >= 20)) else 2\n",
    "        \n",
    "    return [diff, p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "c04f8067c2a3971de8cc0bd521732e18b78ee4c5"
   },
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "    '''\n",
    "    cleans original input data (modifies source dataframe)\n",
    "    '''\n",
    "    warnings.simplefilter(action = 'ignore')\n",
    "    \n",
    "    # Removing empty features\n",
    "    nun = data.nunique()\n",
    "    empty = list(nun[nun <= 1].index)\n",
    "    \n",
    "    data.drop(empty, axis = 1, inplace = True)\n",
    "    print('After removing empty features there are {0:d} features'.format(data.shape[1]))\n",
    "    \n",
    "    # Removing features with the same distribution on 0 and 1 classes\n",
    "    corr = pd.DataFrame(index = ['diff', 'p'])\n",
    "    ind = data[data['TARGET'].notnull()].index\n",
    "    \n",
    "    for c in data.columns.drop('TARGET'):\n",
    "#         corr[c] = corr_feature_with_target(data.loc[ind, c], data.loc[ind, 'TARGET'])\n",
    "        corr[c] = corr_feature_with_target(data[c][ind], data['TARGET'][ind])\n",
    "\n",
    "    corr = corr.T\n",
    "    corr['diff_norm'] = abs(corr['diff'] / data.mean(axis = 0))\n",
    "    \n",
    "    to_del_1 = corr[((corr['diff'] == 0) & (corr['p'] > .05))].index\n",
    "    to_del_2 = corr[((corr['diff_norm'] < .5) & (corr['p'] > .05))].drop(to_del_1).index\n",
    "    to_del = list(to_del_1) + list(to_del_2)\n",
    "    if 'SK_ID_CURR' in to_del:\n",
    "        to_del.remove('SK_ID_CURR')\n",
    "        \n",
    "    data.drop(to_del, axis = 1, inplace = True)\n",
    "    print('After removing features with the same distribution on 0 and 1 classes there are {0:d} features'.format(data.shape[1]))\n",
    "    \n",
    "    # Removing features with not the same distribution on train and test datasets\n",
    "    corr_test = pd.DataFrame(index = ['diff', 'p'])\n",
    "    target = data['TARGET'].notnull().astype(int)\n",
    "    \n",
    "    for c in data.columns.drop('TARGET'):\n",
    "        corr_test[c] = corr_feature_with_target(data[c], target)\n",
    "\n",
    "    corr_test = corr_test.T\n",
    "    corr_test['diff_norm'] = abs(corr_test['diff'] / data.mean(axis = 0))\n",
    "    \n",
    "    bad_features = corr_test[((corr_test['p'] < .05) & (corr_test['diff_norm'] > 1))].index\n",
    "    bad_features = corr.loc[bad_features][corr['diff_norm'] == 0].index\n",
    "    \n",
    "    data.drop(bad_features, axis = 1, inplace = True)\n",
    "    print('After removing features with not the same distribution on train and test datasets there are {0:d} features'.format(data.shape[1]))\n",
    "    \n",
    "    del corr, corr_test\n",
    "    gc.collect()\n",
    "    \n",
    "    # Removing features not interesting for classifier\n",
    "    clf = LGBMClassifier(random_state = 0)\n",
    "    train_index = data[data['TARGET'].notnull()].index\n",
    "    train_columns = data.drop('TARGET', axis = 1).columns\n",
    "\n",
    "    score = 1\n",
    "    new_columns = []\n",
    "    while score > .78:\n",
    "        train_columns = train_columns.drop(new_columns)\n",
    "        clf.fit(data.loc[train_index, train_columns], data.loc[train_index, 'TARGET'])\n",
    "        f_imp = pd.Series(clf.feature_importances_, index = train_columns)\n",
    "        score = roc_auc_score(data.loc[train_index, 'TARGET'], \n",
    "                              clf.predict_proba(data.loc[train_index, train_columns])[:, 1])\n",
    "        new_columns = f_imp[f_imp > 0].index\n",
    "\n",
    "    data.drop(train_columns, axis = 1, inplace = True)\n",
    "    print('After removing features not interesting for classifier there are {0:d} features'.format(data.shape[1]))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# df = pd.read_pickle(f'{file_path}aggregated_df2_cleaned.pkl.zip')\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# feats = [f for f in df.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n",
    "# X = df[df['TARGET'].notnull()][feats]\n",
    "# y = df[df['TARGET'].notnull()]['TARGET']\n",
    "# del df\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X.shape, y.shape)\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# from boostaroota import BoostARoota\n",
    "# br = BoostARoota(metric='auc', iters = 6)\n",
    "# br.fit(X, y)\n",
    "# pd.DataFrame(list(br.keep_vars_)).sort_values(by=0).to_csv(f'boostaroota_{len(list(br.keep_vars_))}_keep_vars.csv',\n",
    "#                                                            index = False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# remaining_vars = list(br.keep_vars_)\n",
    "# print(len(remaining_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# [f for f in df.columns if f in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ['SK_ID_CURR', 'TARGET'] + remaining_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[['SK_ID_CURR', 'TARGET'] + remaining_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_pickle(f'{file_path}aggregated_df2_boostarooted314.pkl.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df[remaining_vars].select_dtypes(include=[np.int16, np.uint32, np.uint8]).nunique(axis=0, dropna = False).sort_value()\n",
    "# categorical_feats = df[remaining_vars].nunique(axis=0, dropna = False)\\\n",
    "#                     .loc[df[remaining_vars].nunique(axis=0, dropna = False)<100].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[categorical_feats]= df[categorical_feats].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# df = pd.read_pickle(f'{file_path}aggregated_df2_boostarooted314.pkl.zip')\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SK_ID_CURR\n",
       "100001    0.000000\n",
       "100002    0.000000\n",
       "100003    0.000000\n",
       "100004    0.000000\n",
       "100005    0.000000\n",
       "100006    0.000000\n",
       "100007    0.000000\n",
       "100008    0.083333\n",
       "100009    0.000000\n",
       "100010    0.000000\n",
       "Name: PAID, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_paid = pd.read_pickle(f'{file_path}prev_paid_series.pkl.zip')\n",
    "prev_paid.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "338857"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prev_paid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_features =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 356244 entries, 0 to 356243\n",
      "Columns: 287 entries, ('amax', 'AMT_CREDIT_MAX_OVERDUE', 'Active') to app most popular AMT_GOODS_PRICE\n",
      "dtypes: float16(49), float32(133), float64(51), int16(18), int32(8), int8(6), uint16(1), uint32(1), uint8(20)\n",
      "memory usage: 386.6 MB\n",
      "Wall time: 3.38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "iv_extended_feat = pd.read_pickle(f'{file_path}iv_extended_feat.pkl.zip')\n",
    "processed_features = list(set(processed_features) | set(iv_extended_feat.columns))\n",
    "iv_extended_feat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 356244 entries, 0 to 356243\n",
      "Columns: 286 entries, SK_ID_CURR to ('mean', 'AMT_DOWN_PAYMENT', 'XNA')\n",
      "dtypes: float16(48), float32(133), float64(51), int16(18), int32(8), int8(6), uint16(1), uint32(1), uint8(20)\n",
      "memory usage: 385.9 MB\n"
     ]
    }
   ],
   "source": [
    "iv_extended_feat_imp_feat = pd.read_csv(f'{file_path}leonid23(iv_ext)_fi_sorted.csv').iloc[:,0].tolist()\n",
    "iv_extended_feat = iv_extended_feat[['SK_ID_CURR'] + iv_extended_feat_imp_feat]\n",
    "iv_extended_feat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 356251 entries, 0 to 356254\n",
      "Columns: 721 entries, index to CC_COUNT\n",
      "dtypes: float16(289), float32(135), float64(139), int16(2), int8(1), uint32(2), uint8(153)\n",
      "memory usage: 816.8 MB\n",
      "Wall time: 56.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df4 = pd.read_pickle('../data/df.pkl.gz')\n",
    "# df4 = df4.join(pd.DataFrame(prev_paid), on='SK_ID_CURR')\n",
    "# df4['PAID'].fillna(0, inplace = True)\n",
    "df4 = gentle_reduce_mem_usage(df4, verbose = False)\n",
    "df4.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 356251 entries, 0 to 356254\n",
      "Columns: 495 entries, SK_ID_CURR to BURO_CREDIT_CURRENCY_currency 1_MEAN\n",
      "dtypes: float16(174), float32(114), float64(132), uint32(1), uint8(74)\n",
      "memory usage: 661.1 MB\n"
     ]
    }
   ],
   "source": [
    "df4_important_features = pd.read_csv(f'{file_path}leonid22_fi_sorted.csv').iloc[:,0].tolist()\n",
    "df4_important_features = [f for f in df4_important_features if f not in ['TARGET','SK_ID_BUREAU','SK_ID_PREV',\n",
    "                                                                 'index', 'PAID'] + processed_features + USELESS_COLUMNS\\\n",
    "                                                             + [x for x in df4_important_features if 'SK_ID_'  in x]]\n",
    "processed_features = list(set(processed_features) | set(df4.columns))\n",
    "df4 = df4[['SK_ID_CURR'] + df4_important_features]\n",
    "df4.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 356255 entries, 0 to 356254\n",
      "Columns: 823 entries, SK_ID_CURR to CLOSED_DPD_1 / Month_MIN_STD\n",
      "dtypes: float16(462), float32(268), float64(27), uint32(1), uint8(65)\n",
      "memory usage: 775.0 MB\n",
      "Wall time: 10.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df3 = pd.read_pickle(f'{file_path}data_7_house_leak_paid.pkl.zip')\n",
    "df3_important_features = pd.read_csv(f'{file_path}leonid15_fi_sorted.csv').iloc[:,0].tolist()\n",
    "df3_important_features = [f for f in df3_important_features if f not in ['TARGET','SK_ID_BUREAU','SK_ID_PREV',\n",
    "                                                                 'index', 'PAID'] + processed_features + USELESS_COLUMNS\\\n",
    "                                                             + [x for x in df3_important_features if 'SK_ID_'  in x]]\n",
    "processed_features = list(set(processed_features) | set(df3.columns))\n",
    "df3 = df3[['SK_ID_CURR', 'TARGET'] + df3_important_features]\n",
    "df3.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df2 = pd.read_pickle(f'{file_path}aggregated_df2_boostarooted314.pkl.zip')\n",
    "df2_important_features = [f for f in df2.columns.tolist() if f not in ['TARGET','SK_ID_BUREAU','SK_ID_PREV',\n",
    "                                                                 'index', 'PAID'] + processed_features + USELESS_COLUMNS\\\n",
    "                                                             + [x for x in df2.columns.tolist() if 'SK_ID_'  in x]]\n",
    "df2 = df2[['SK_ID_CURR'] + df2_important_features]\n",
    "# df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 28.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "aggregated_df2 = pd.read_pickle(f'{file_path}aggregated_df2.pkl.zip')\n",
    "processed_features = list(set(processed_features) | set(aggregated_df2.columns))\n",
    "del aggregated_df2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 356255 entries, 0 to 356254\n",
      "Columns: 1644 entries, SK_ID_CURR to CARD_card AMT_BALANCE - AMT_RECIVABLE_VAR\n",
      "dtypes: float16(697), float32(523), float64(358), uint32(1), uint8(65)\n",
      "memory usage: 2.1 GB\n",
      "Wall time: 4min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_extended = df3.merge(iv_extended_feat, on='SK_ID_CURR', how='left')\n",
    "df_extended = df_extended.merge(df4, on='SK_ID_CURR', how='left')\n",
    "df_extended = df_extended.merge(df2, on='SK_ID_CURR', how='left')\n",
    "df_extended.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48744, 1644)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_extended[df_extended['TARGET'].isnull()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strong_features = pd.read_csv(f'{file_path}leonid24(df_ext01)_fi_strong.csv').iloc[:,0].tolist()\n",
    "len(strong_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "strong_features = [f for f in df_extended.columns.tolist() if f in strong_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "strong_features = [f for f in strong_features if f not in ['TARGET','SK_ID_BUREAU','SK_ID_PREV',\n",
    "                                                                 'index', 'PAID'] + USELESS_COLUMNS\\\n",
    "                                                             + [x for x in strong_features if 'SK_ID_'  in x]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "484"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(strong_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:139: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:141: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 356255 entries, 0 to 356254\n",
      "Columns: 486 entries, SK_ID_CURR to REFUSED_prev missing_SUM\n",
      "dtypes: float16(182), float32(214), float64(89), uint32(1)\n",
      "memory usage: 660.5 MB\n",
      "Wall time: 1min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_extended = df_extended[['SK_ID_CURR', 'TARGET'] + strong_features]\n",
    "df_extended = gentle_reduce_mem_usage(df_extended, verbose = False)\n",
    "df_extended.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4407"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processed_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-b0815f0d78b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mdel\u001b[0m \u001b[0mdf2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miv_extended_feat\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df2' is not defined"
     ]
    }
   ],
   "source": [
    "del df2, df3, df4, iv_extended_feat\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 356244 entries, 0 to 356243\n",
      "Data columns (total 70 columns):\n",
      "SK_ID_CURR                                                  356244 non-null uint32\n",
      "FLAG_DOCUMENT_11                                            356244 non-null uint8\n",
      "FLAG_DOCUMENT_18                                            356244 non-null uint8\n",
      "FLAG_DOCUMENT_6                                             356244 non-null uint8\n",
      "FLAG_DOCUMENT_8                                             356244 non-null uint8\n",
      "BURO_DPD_4_cnt_SIZE_VAR                                     116902 non-null float16\n",
      "BURO_AMT_CREDIT_SUM_DEBT_VAR                                249145 non-null float32\n",
      "BURO_AMT_CREDIT_MAX_OVERDUE_VAR                             136563 non-null float32\n",
      "BURO_DPD_0_cnt_MAX_VAR                                      110169 non-null float16\n",
      "BURO_DPD_4 / Month_MAX_VAR                                  742 non-null float16\n",
      "BURO_AMT_CREDIT_SUM_OVERDUE_VAR                             264285 non-null float32\n",
      "BURO_DPD_3 / Month_MIN_VAR                                  1083 non-null float16\n",
      "BURO_Month_MAX_VAR                                          116902 non-null float16\n",
      "BURO_DPD_2 / Month_MAX_VAR                                  2466 non-null float16\n",
      "BURO_When_closed_MIN_VAR                                    81303 non-null float16\n",
      "BURO_CNT_CREDIT_PROLONG_VAR                                 264285 non-null float16\n",
      "BURO_DAYS_ENDDATE_FACT_VAR                                  206601 non-null float32\n",
      "BURO_AMT_CREDIT_SUM_VAR                                     264283 non-null float32\n",
      "BURO_DPD_0_cnt_MIN_VAR                                      110169 non-null float16\n",
      "BURO_AMT_ANNUITY_VAR                                        92399 non-null float32\n",
      "BURO_DPD_1_cnt_MIN_VAR                                      22293 non-null float16\n",
      "BURO_DPD_1 / Month_MAX_VAR                                  22291 non-null float16\n",
      "BURO_MONTHS_BALANCE_MIN_VAR                                 116902 non-null float16\n",
      "BURO_DAYS_CREDIT_UPDATE_VAR                                 264282 non-null float32\n",
      "BURO_DPD_2_cnt_MIN_VAR                                      2466 non-null float16\n",
      "BURO_MONTHS_BALANCE_MAX_VAR                                 116902 non-null float16\n",
      "BURO_DAYS_CREDIT_ENDDATE_VAR                                258895 non-null float32\n",
      "BURO_bureau DAYS_CREDIT - DAYS_CREDIT_ENDDATE_VAR           258895 non-null float32\n",
      "BURO_DPD_5_cnt_MAX_VAR                                      762 non-null float16\n",
      "BURO_bureau AMT_CREDIT_SUM - AMT_CREDIT_SUM_DEBT_VAR        249143 non-null float32\n",
      "BURO_bureau DAYS_CREDIT_ENDDATE - DAYS_ENDDATE_FACT_VAR     203797 non-null float32\n",
      "BURO_bureau DAYS_CREDIT - DAYS_ENDDATE_FACT_VAR             206601 non-null float32\n",
      "BURO_Month_closed_to_end_MIN_VAR                            81303 non-null float16\n",
      "BURO_bureau AMT_CREDIT_SUM - AMT_CREDIT_SUM_OVERDUE_VAR     264283 non-null float32\n",
      "BURO_AMT_CREDIT_SUM_LIMIT_VAR                               221796 non-null float32\n",
      "BURO_bureau DAYS_CREDIT_UPDATE - DAYS_CREDIT_ENDDATE_VAR    258892 non-null float32\n",
      "BURO_DPD_0 / Month_MIN_VAR                                  107322 non-null float16\n",
      "BURO_DPD_0 / Month_MAX_VAR                                  107322 non-null float16\n",
      "BURO_bureau DAYS_CREDIT - CREDIT_DAY_OVERDUE_VAR            264285 non-null float32\n",
      "BURO_bureau AMT_CREDIT_SUM - AMT_CREDIT_SUM_LIMIT_VAR       221796 non-null float32\n",
      "BURO_Non_zero_DPD_cnt_MIN_VAR                               116902 non-null float16\n",
      "BURO_DPD_5 / Month_MAX_VAR                                  762 non-null float16\n",
      "BURO_Month_closed_to_end_MAX_VAR                            81303 non-null float16\n",
      "BURO_Non_zero_DPD_cnt_MAX_VAR                               116902 non-null float16\n",
      "BURO_DPD_5 / Month_MIN_VAR                                  762 non-null float16\n",
      "BURO_CREDIT_DAY_OVERDUE_VAR                                 264285 non-null float32\n",
      "PREV_HOUR_APPR_PROCESS_START_MIN                            338851 non-null float16\n",
      "PREV_HOUR_APPR_PROCESS_START_VAR                            278393 non-null float16\n",
      "PREV_HOUR_APPR_PROCESS_START_SUM                            338851 non-null float16\n",
      "PREV_CNT_PAYMENT_MIN                                        338373 non-null float16\n",
      "PREV_CNT_PAYMENT_MAX                                        338373 non-null float16\n",
      "PREV_NFLAG_LAST_APPL_IN_DAY_MEAN                            338851 non-null float16\n",
      "PREV_NFLAG_LAST_APPL_IN_DAY_VAR                             278393 non-null float16\n",
      "PREV_NFLAG_LAST_APPL_IN_DAY_SUM                             338851 non-null float16\n",
      "PREV_NFLAG_INSURED_ON_APPROVAL_MEAN                         337334 non-null float16\n",
      "PREV_NFLAG_INSURED_ON_APPROVAL_VAR                          245443 non-null float16\n",
      "PREV_NFLAG_INSURED_ON_APPROVAL_SUM                          338851 non-null float16\n",
      "POS_SK_DPD_VAR                                              336874 non-null float32\n",
      "POS_CNT_INSTALMENT_VAR                                      336852 non-null float16\n",
      "POS_MOST_NAME_CONTRACT_STATUS_MOST_FREQ_CAT                 337246 non-null float16\n",
      "INS_DAYS_ENTRY_PAYMENT_VAR                                  338604 non-null float32\n",
      "INS_NUM_INSTALMENT_VERSION_MAX                              339581 non-null float16\n",
      "INS_NUM_INSTALMENT_VERSION_MEAN                             339581 non-null float16\n",
      "INS_ins NUM_INSTALMENT_NUMBER_100_VAR                       338609 non-null float16\n",
      "INS_ins DAYS_INSTALMENT more NUM_INSTALMENT_NUMBER_VAR      338609 non-null float16\n",
      "INS_ins AMT_PAYMENT / AMT_INSTALMENT_VAR                    338585 non-null float32\n",
      "INS_AMT_INSTALMENT_VAR                                      338609 non-null float32\n",
      "INS_ins AMT_INSTALMENT - AMT_PAYMENT_VAR                    338604 non-null float32\n",
      "INS_ins DAYS_ENTRY_PAYMENT - DAYS_INSTALMENT_VAR            338604 non-null float32\n",
      "INS_AMT_PAYMENT_VAR                                         338604 non-null float32\n",
      "dtypes: float16(40), float32(25), uint32(1), uint8(4)\n",
      "memory usage: 63.9 MB\n",
      "Wall time: 1.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# tearth_cat6 = pd.read_csv('../features/tEarth_cat6.csv')\n",
    "tearth_cat6 = pd.read_pickle(f'{file_path}tearth_cat6.pkl.zip')\n",
    "tearth_cat6.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# tearth_cat6_imp_f = [f for f in tearth_cat6.columns.tolist() if f not in ['TARGET','SK_ID_BUREAU','SK_ID_PREV',\n",
    "#                                                                  'index', 'PAID'] + processed_features + USELESS_COLUMNS\\\n",
    "#                                                              + [x for x in tearth_cat6.columns.tolist() if 'SK_ID_'  in x]  ]\n",
    "processed_features = list(set(processed_features) | set(tearth_cat6.columns.tolist()))\n",
    "# tearth_cat6 = tearth_cat6[['SK_ID_CURR'] + tearth_cat6_imp_f]\n",
    "# tearth_cat6 = gentle_reduce_mem_usage(tearth_cat6, verbose = False)\n",
    "# tearth_cat6.to_pickle(f'{file_path}tearth_cat6.pkl.zip')\n",
    "# tearth_cat6.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 356244 entries, 0 to 356243\n",
      "Data columns (total 12 columns):\n",
      "SK_ID_CURR    356244 non-null int64\n",
      "pca_col_0     356244 non-null float64\n",
      "pca_col_1     356244 non-null float64\n",
      "pca_col_2     356244 non-null float64\n",
      "pca_col_3     356244 non-null float64\n",
      "pca_col_4     356244 non-null float64\n",
      "pca_col_5     356244 non-null float64\n",
      "pca_col_6     356244 non-null float64\n",
      "pca_col_7     356244 non-null float64\n",
      "pca_col_8     356244 non-null float64\n",
      "pca_col_9     356244 non-null float64\n",
      "cluster       356244 non-null int64\n",
      "dtypes: float64(10), int64(2)\n",
      "memory usage: 32.6 MB\n",
      "Wall time: 396 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# pca_cluster = pd.concat([pd.read_csv(f'{file_path}pca+cluster/iv_train_stack_feat.csv'),\n",
    "#                       pd.read_csv(f'{file_path}pca+cluster/iv_test_stack_feat.csv')], ignore_index=True,\n",
    "#                      axis=0, verify_integrity=True)\n",
    "# pca_cluster.to_pickle(f'{file_path}iv_pca_cluster.pkl.zip')\n",
    "pca_cluster = pd.read_pickle(f'{file_path}iv_pca_cluster.pkl.zip')\n",
    "processed_features = list(set(processed_features) | set(pca_cluster.columns.tolist()))\n",
    "pca_cluster.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# iv_extended_v2_feat_train = pd.read_csv(f'{file_path}iv ext feat v.2/iv_train_383feat.csv')\n",
    "# iv_extended_v2_feat_target = pd.read_csv(f'{file_path}iv ext feat v.2/iv_target.csv',\n",
    "#                       header = None, names = ['SK_ID_CURR', 'TARGET'])\n",
    "# iv_extended_v2_feat_test = pd.read_csv(f'{file_path}iv ext feat v.2/iv_test_383feat.csv')\n",
    "# iv_extended_v2_feat_train = iv_extended_v2_feat_train.merge(iv_extended_v2_feat_target,\n",
    "#                                                      on='SK_ID_CURR')\n",
    "# iv_extended_v2_feat = pd.concat([iv_extended_v2_feat_train, iv_extended_v2_feat_test],\n",
    "#                              ignore_index = True, axis=0, verify_integrity = True)\n",
    "# # iv_extended_v2_feat = gentle_reduce_mem_usage(iv_extended_v2_feat, verbose = False)\n",
    "# del iv_extended_v2_feat_train, iv_extended_v2_feat_target, iv_extended_v2_feat_test\n",
    "# gc.collect()\n",
    "# # iv_extended_v2_feat.to_pickle(f'{file_path}iv_extended_v2_feat_full.pkl.zip')\n",
    "iv_extended_v2_feat = pd.read_pickle(f'{file_path}iv_extended_v2_feat_full.pkl.zip')\n",
    "# iv_extended_v2_feat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "iv_extended_v2_imp_f = [f for f in iv_extended_v2_feat.columns.tolist() if f not in ['TARGET','SK_ID_BUREAU','SK_ID_PREV',\n",
    "                                                                 'index', 'PAID'] + processed_features + USELESS_COLUMNS\\\n",
    "                                                      + [x for x in iv_extended_v2_feat.columns.tolist() if 'SK_ID_'  in x]  ]\n",
    "processed_features = list(set(processed_features) | set(iv_extended_v2_feat.columns.tolist()))\n",
    "iv_extended_v2_feat = iv_extended_v2_feat[['SK_ID_CURR'] + iv_extended_v2_imp_f]\n",
    "# len(iv_extended_v2_imp_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'processed_features': processed_features}).to_pickle(f'{file_path}processed_features_v3.pkl.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_features = pd.read_pickle(f'{file_path}processed_features_v2.pkl.zip')['processed_features'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 356255 entries, 0 to 356254\n",
      "Columns: 566 entries, SK_ID_CURR to cluster\n",
      "dtypes: float16(227), float32(239), float64(99), uint32(1)\n",
      "memory usage: 752.2 MB\n",
      "Wall time: 1min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_extended = df_extended.merge(tearth_cat6, on='SK_ID_CURR', how='left')\n",
    "df_extended = df_extended.merge(pca_cluster, on='SK_ID_CURR', how='left')\n",
    "df_extended = df_extended.merge(iv_extended_v2_feat, on='SK_ID_CURR', how='left')\n",
    "df_extended = gentle_reduce_mem_usage(df_extended, verbose = False)\n",
    "df_extended.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[\\'[\\' \"\\'\" \\'S\\' ... \\'3\\' \\'3\\' \\']\\'] not in index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2680\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2681\u001b[0m             \u001b[1;31m# either boolean or fancy integer index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2682\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2683\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2684\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2724\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2725\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2726\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2727\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[0;32m   1325\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m                     raise KeyError('{mask} not in index'\n\u001b[1;32m-> 1327\u001b[1;33m                                    .format(mask=objarr[mask]))\n\u001b[0m\u001b[0;32m   1328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values_from_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '[\\'[\\' \"\\'\" \\'S\\' ... \\'3\\' \\'3\\' \\']\\'] not in index'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gp123_no_ext = pd.read_pickle(f'{file_path}gp123-no-ext-source.pkl')\n",
    "gp123_no_ext_f = [str(f) for f in str(gp123_no_ext.columns.tolist()) if f not in ['TARGET','SK_ID_BUREAU','SK_ID_PREV',\n",
    "                                                                 'index', 'PAID'] + processed_features + USELESS_COLUMNS\\\n",
    "                                                      + [x for x in str(gp123_no_ext.columns.tolist()) if 'SK_ID_'  in x]  ]\n",
    "gp123_no_ext = gp123_no_ext[['SK_ID_CURR'] + gp123_no_ext_f]\n",
    "processed_features = list(set(processed_features) | set(gp123_no_ext.columns.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "neptune_ml_features = pd.read_pickle(f'{file_path}neptune_ml_features.pkl.zip')\n",
    "neptune_installments = pd.read_pickle(f'{file_path}neptune_installments.pkl.zip')\n",
    "neptune_pos = pd.read_pickle(f'{file_path}neptune_pos.pkl.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_extended = df_extended.merge(gp123_no_ext, on='SK_ID_CURR', how='left')\n",
    "df_extended = df_extended.merge(neptune_ml_features, on='SK_ID_CURR', how='left')\n",
    "df_extended = df_extended.merge(neptune_installments, on='SK_ID_CURR', how='left')\n",
    "df_extended = df_extended.merge(neptune_pos, on='SK_ID_CURR', how='left')\n",
    "df_extended.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in str(df_extended.columns.tolist()) if 'external'  in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extended.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'df_extended_columns': df_extended.columns.tolist()}).to_csv(f'{file_path}df_extended_columns.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_ext = [x for x in df_extended.columns.tolist() if 'EXT_SOURCE'  in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_extended.drop(remove_ext, axis=1, inplace=True)\n",
    "df_extended.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extended[df_extended['TARGET'].isnull()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extended = gentle_reduce_mem_usage(df_extended, verbose = False)\n",
    "df_extended.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extended.to_pickle(f'{file_path}df_extended_v2.pkl.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "gp123 = pd.read_pickle(f'{file_path}gp123.pkl')\n",
    "gp123.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extended.to_pickle(f'{file_path}df_extended.pkl.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_extended = pd.read_pickle(f'{file_path}df_extended.pkl.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extended2 = df_extended.join(pd.DataFrame(prev_paid), on='SK_ID_CURR')\n",
    "df_extended2['PAID'].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
