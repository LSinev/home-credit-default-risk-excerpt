{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ca25a2f95f0fc9498b9b2e3a9d96607fbb682015"
   },
   "source": [
    "# Home Credit Default Risk 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "cc4088625ae2209899d05c70dfd7bcb108cb4c3a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "warnings.simplefilter(action = 'ignore', category = FutureWarning)\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except:\n",
    "    import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 2042\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../input/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.read_csv(f'{file_path}sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "be294207f4e12ccf54d922814789b27998577dca"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dask.distributed import Client\n",
    "\n",
    "# # If you have a remote cluster running Dask\n",
    "# # client = Client('tcp://scheduler-address:8786')\n",
    "\n",
    "# # If you want Dask to set itself up on your personal computer\n",
    "# client = Client(processes=False)\n",
    "\n",
    "# from joblib import parallel_backend, Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "962799c45d0c88ee9237cb0e202b11758abac536"
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "42960cc0257a40fee0876294c6956e0aeba23023"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ranksums\n",
    "from scipy.stats import gmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "0b5e7cfa7c94294ad8b1eab00438592d24450e11"
   },
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "USELESS_COLUMNS = ['FLAG_DOCUMENT_10',\n",
    "                   'FLAG_DOCUMENT_12',\n",
    "                   'FLAG_DOCUMENT_13',\n",
    "                   'FLAG_DOCUMENT_14',\n",
    "                   'FLAG_DOCUMENT_15',\n",
    "                   'FLAG_DOCUMENT_16',\n",
    "                   'FLAG_DOCUMENT_17',\n",
    "                   'FLAG_DOCUMENT_19',\n",
    "                   'FLAG_DOCUMENT_2',\n",
    "                   'FLAG_DOCUMENT_20',\n",
    "                   'FLAG_DOCUMENT_21']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "32f2b23ed9dabb4b8ec59cc86f1e9cecdc9abad3"
   },
   "source": [
    "## Aggregating datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3687d746e5fe89d3477cff12521e1402431c7ab1"
   },
   "source": [
    "### Service functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "4b1d9d1291ce3da6dc089ec6c3918f485528caf0"
   },
   "outputs": [],
   "source": [
    "def convert_col_to_proper_int(df_col):\n",
    "    col_type = df_col.dtype\n",
    "#     print('convert_col_to_proper_int column: ', df_col.name, 'type: ', col_type, 'c_min: ', c_min)\n",
    "    if ((str(col_type)[:3] == 'int') | (str(col_type)[:4] == 'uint')): # | (str(col_type)[:5] == 'float')\n",
    "        c_min = df_col.min()\n",
    "        c_max = df_col.max()\n",
    "        if c_min < 0:\n",
    "#             print('c_min: ', c_min, 'less 0')\n",
    "            if c_min >= np.iinfo(np.int8).min and c_max <= np.iinfo(np.int8).max:\n",
    "                df_col = df_col.astype(np.int8)\n",
    "            elif c_min >= np.iinfo(np.int16).min and c_max <= np.iinfo(np.int16).max:\n",
    "                df_col = df_col.astype(np.int16)\n",
    "            elif c_min >= np.iinfo(np.int32).min and c_max <= np.iinfo(np.int32).max:\n",
    "                df_col = df_col.astype(np.int32)\n",
    "            elif c_min >= np.iinfo(np.int64).min and c_max <= np.iinfo(np.int64).max:\n",
    "                df_col = df_col.astype(np.int64)\n",
    "        else:\n",
    "#             print('c_min: ', c_min, 'not less 0')\n",
    "            if c_max <= np.iinfo(np.uint8).max:\n",
    "                df_col = df_col.astype(np.uint8)\n",
    "            elif c_max <= np.iinfo(np.uint16).max:\n",
    "                df_col = df_col.astype(np.uint16)\n",
    "            elif c_max <= np.iinfo(np.uint32).max:\n",
    "                df_col = df_col.astype(np.uint32)\n",
    "            elif c_max <= np.iinfo(np.uint64).max:\n",
    "                df_col = df_col.astype(np.uint64)\n",
    "            \n",
    "    return df_col\n",
    "\n",
    "def convert_col_to_proper_float(df_col):\n",
    "    col_type = df_col.dtype\n",
    "    if str(col_type)[:5] == 'float':\n",
    "        unique_count = len(np.unique(df_col))\n",
    "        df_col_temp = df_col.astype(np.float32)\n",
    "        if len(np.unique(df_col_temp)) == unique_count:\n",
    "            df_col = df_col_temp\n",
    "            c_min = df_col.min()\n",
    "            c_max = df_col.max()\n",
    "            if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                df_col_temp = df_col.astype(np.float16)\n",
    "                if len(np.unique(df_col_temp)) == unique_count:\n",
    "                    df_col = df_col_temp\n",
    "            \n",
    "    return df_col\n",
    "\n",
    "\n",
    "\n",
    "def float_to_int(df):\n",
    "    \"\"\" iterate through all float columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.\n",
    "    \"\"\"\n",
    "#     print('Begin float_to_int')\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "#         print('column: ', col, 'type: ', col_type)\n",
    "        if str(col_type)[:5] == 'float':\n",
    "            if (df[col] % 1 == 0).all():\n",
    "                df[col] = convert_col_to_proper_int(df[col].astype(np.int64))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def float_reduced(df):\n",
    "    \"\"\" iterate through all float columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.\n",
    "    \"\"\"\n",
    "#     print('Begin float_reduced')\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "#         print('column: ', col, 'type: ', col_type)\n",
    "        if str(col_type)[:5] == 'float':\n",
    "            df[col] = convert_col_to_proper_float(df[col])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def int_reduced(df):\n",
    "    \"\"\" iterate through all int columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.\n",
    "    \"\"\"\n",
    "#     print('Begin float_reduced')\n",
    "    for col in df.columns:\n",
    "        df[col] = convert_col_to_proper_int(df[col])\n",
    "    \n",
    "    return df\n",
    "\n",
    "## Thanks You Guillaume Martin for the Awesome Memory Optimizer!\n",
    "## https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\n",
    "def reduce_mem_usage(data, verbose = True):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.\n",
    "    \"\"\"\n",
    "    start_mem = data.memory_usage().sum() / 1024**2\n",
    "    if verbose:\n",
    "        print('Memory usage of dataframe: {:.2f} MB'.format(start_mem))\n",
    "\n",
    "    for col in data.columns:\n",
    "#         print(col, type(data[col]), data[col].shape)\n",
    "        col_type = data[col].dtype\n",
    "\n",
    "        if ((col_type != object) & (col_type != '<M8[ns]') & (col_type.name != 'category')):#\n",
    "            c_min = data[col].min()\n",
    "            c_max = data[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                data[col] = convert_col_to_proper_int(data[col])\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    data[col] = data[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    data[col] = data[col].astype(np.float32)\n",
    "                else:\n",
    "                    data[col] = data[col].astype(np.float64)\n",
    "        else: data[col] = data[col].astype('category')\n",
    "\n",
    "    end_mem = data.memory_usage().sum() / 1024**2\n",
    "    if verbose:\n",
    "        print('Memory usage after optimization: {:.2f} MB'.format(end_mem))\n",
    "        print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "\n",
    "    return data\n",
    "\n",
    "def gentle_reduce_mem_usage(data, verbose = True):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.\n",
    "    \"\"\"\n",
    "    start_mem = data.memory_usage().sum() / 1024**2\n",
    "    if verbose:\n",
    "        print('Memory usage of dataframe: {:.2f} MB'.format(start_mem))\n",
    "\n",
    "    for col in data.columns:\n",
    "#         print(col, type(data[col]), data[col].shape)\n",
    "        col_type = data[col].dtype\n",
    "\n",
    "        if ((col_type != object) & (col_type != '<M8[ns]') & (col_type.name != 'category')):#\n",
    "            c_min = data[col].min()\n",
    "            c_max = data[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                data[col] = convert_col_to_proper_int(data[col])\n",
    "            else:\n",
    "                if (data[col] % 1 == 0).all():\n",
    "                    data[col] = convert_col_to_proper_int(data[col].astype(np.int64))\n",
    "                else:\n",
    "                    data[col] = convert_col_to_proper_float(data[col])\n",
    "        else: data[col] = data[col].astype('category')\n",
    "\n",
    "    end_mem = data.memory_usage().sum() / 1024**2\n",
    "    if verbose:\n",
    "        print('Memory usage after optimization: {:.2f} MB'.format(end_mem))\n",
    "        print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3cdf22861b989e1dfe6331ecef61b13ef3fa2d05"
   },
   "source": [
    "## Cleaning dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "c8536f211c9768b6f7622a43413e8bdd2a46092d"
   },
   "outputs": [],
   "source": [
    "def corr_feature_with_target(feature, target):\n",
    "    c0 = feature[target == 0].dropna()\n",
    "    c1 = feature[target == 1].dropna()\n",
    "        \n",
    "    if set(feature.unique()) == set([0, 1]):\n",
    "        diff = abs(np.mean(c0, axis=0) - np.mean(c1, axis=0))\n",
    "    else:\n",
    "        diff = abs(np.median(c0, axis=0) - np.median(c1, axis=0))\n",
    "        \n",
    "    p = ranksums(c0, c1)[1] if ((len(c0) >= 20) & (len(c1) >= 20)) else 2\n",
    "        \n",
    "    return [diff, p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "c04f8067c2a3971de8cc0bd521732e18b78ee4c5"
   },
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "    '''\n",
    "    cleans original input data (modifies source dataframe)\n",
    "    '''\n",
    "    warnings.simplefilter(action = 'ignore')\n",
    "    \n",
    "    # Removing empty features\n",
    "    nun = data.nunique()\n",
    "    empty = list(nun[nun <= 1].index)\n",
    "    \n",
    "    data.drop(empty, axis = 1, inplace = True)\n",
    "    print('After removing empty features there are {0:d} features'.format(data.shape[1]))\n",
    "    \n",
    "    # Removing features with the same distribution on 0 and 1 classes\n",
    "    corr = pd.DataFrame(index = ['diff', 'p'])\n",
    "    ind = data[data['TARGET'].notnull()].index\n",
    "    \n",
    "    for c in data.columns.drop('TARGET'):\n",
    "#         corr[c] = corr_feature_with_target(data.loc[ind, c], data.loc[ind, 'TARGET'])\n",
    "        corr[c] = corr_feature_with_target(data[c][ind], data['TARGET'][ind])\n",
    "\n",
    "    corr = corr.T\n",
    "    corr['diff_norm'] = abs(corr['diff'] / data.mean(axis = 0))\n",
    "    \n",
    "    to_del_1 = corr[((corr['diff'] == 0) & (corr['p'] > .05))].index\n",
    "    to_del_2 = corr[((corr['diff_norm'] < .5) & (corr['p'] > .05))].drop(to_del_1).index\n",
    "    to_del = list(to_del_1) + list(to_del_2)\n",
    "    if 'SK_ID_CURR' in to_del:\n",
    "        to_del.remove('SK_ID_CURR')\n",
    "        \n",
    "    data.drop(to_del, axis = 1, inplace = True)\n",
    "    print('After removing features with the same distribution on 0 and 1 classes there are {0:d} features'.format(data.shape[1]))\n",
    "    \n",
    "    # Removing features with not the same distribution on train and test datasets\n",
    "    corr_test = pd.DataFrame(index = ['diff', 'p'])\n",
    "    target = data['TARGET'].notnull().astype(int)\n",
    "    \n",
    "    for c in data.columns.drop('TARGET'):\n",
    "        corr_test[c] = corr_feature_with_target(data[c], target)\n",
    "\n",
    "    corr_test = corr_test.T\n",
    "    corr_test['diff_norm'] = abs(corr_test['diff'] / data.mean(axis = 0))\n",
    "    \n",
    "    bad_features = corr_test[((corr_test['p'] < .05) & (corr_test['diff_norm'] > 1))].index\n",
    "    bad_features = corr.loc[bad_features][corr['diff_norm'] == 0].index\n",
    "    \n",
    "    data.drop(bad_features, axis = 1, inplace = True)\n",
    "    print('After removing features with not the same distribution on train and test datasets there are {0:d} features'.format(data.shape[1]))\n",
    "    \n",
    "    del corr, corr_test\n",
    "    gc.collect()\n",
    "    \n",
    "    # Removing features not interesting for classifier\n",
    "    clf = LGBMClassifier(random_state = 0)\n",
    "    train_index = data[data['TARGET'].notnull()].index\n",
    "    train_columns = data.drop('TARGET', axis = 1).columns\n",
    "\n",
    "    score = 1\n",
    "    new_columns = []\n",
    "    while score > .78:\n",
    "        train_columns = train_columns.drop(new_columns)\n",
    "        clf.fit(data.loc[train_index, train_columns], data.loc[train_index, 'TARGET'])\n",
    "        f_imp = pd.Series(clf.feature_importances_, index = train_columns)\n",
    "        score = roc_auc_score(data.loc[train_index, 'TARGET'], \n",
    "                              clf.predict_proba(data.loc[train_index, train_columns])[:, 1])\n",
    "        new_columns = f_imp[f_imp > 0].index\n",
    "\n",
    "    data.drop(train_columns, axis = 1, inplace = True)\n",
    "    print('After removing features not interesting for classifier there are {0:d} features'.format(data.shape[1]))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# df = pd.read_pickle(f'{file_path}aggregated_df2_cleaned.pkl.zip')\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# feats = [f for f in df.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n",
    "# X = df[df['TARGET'].notnull()][feats]\n",
    "# y = df[df['TARGET'].notnull()]['TARGET']\n",
    "# del df\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X.shape, y.shape)\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# from boostaroota import BoostARoota\n",
    "# br = BoostARoota(metric='auc', iters = 6)\n",
    "# br.fit(X, y)\n",
    "# pd.DataFrame(list(br.keep_vars_)).sort_values(by=0).to_csv(f'boostaroota_{len(list(br.keep_vars_))}_keep_vars.csv',\n",
    "#                                                            index = False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# remaining_vars = list(br.keep_vars_)\n",
    "# print(len(remaining_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# [f for f in df.columns if f in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ['SK_ID_CURR', 'TARGET'] + remaining_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[['SK_ID_CURR', 'TARGET'] + remaining_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_pickle(f'{file_path}aggregated_df2_boostarooted314.pkl.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df[remaining_vars].select_dtypes(include=[np.int16, np.uint32, np.uint8]).nunique(axis=0, dropna = False).sort_value()\n",
    "# categorical_feats = df[remaining_vars].nunique(axis=0, dropna = False)\\\n",
    "#                     .loc[df[remaining_vars].nunique(axis=0, dropna = False)<100].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[categorical_feats]= df[categorical_feats].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# df = pd.read_pickle(f'{file_path}aggregated_df2_boostarooted314.pkl.zip')\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SK_ID_CURR\n",
       "100001    0.000000\n",
       "100002    0.000000\n",
       "100003    0.000000\n",
       "100004    0.000000\n",
       "100005    0.000000\n",
       "100006    0.000000\n",
       "100007    0.000000\n",
       "100008    0.083333\n",
       "100009    0.000000\n",
       "100010    0.000000\n",
       "Name: PAID, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_paid = pd.read_pickle(f'{file_path}prev_paid_series.pkl.zip')\n",
    "prev_paid.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "338857"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prev_paid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 356244 entries, 0 to 356243\n",
      "Columns: 287 entries, ('amax', 'AMT_CREDIT_MAX_OVERDUE', 'Active') to app most popular AMT_GOODS_PRICE\n",
      "dtypes: float16(49), float32(133), float64(51), int16(18), int32(8), int8(6), uint16(1), uint32(1), uint8(20)\n",
      "memory usage: 386.6 MB\n",
      "Wall time: 3.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "iv_extended_feat = pd.read_pickle(f'{file_path}iv_extended_feat.pkl.zip')\n",
    "iv_extended_feat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 356244 entries, 0 to 356243\n",
      "Columns: 286 entries, SK_ID_CURR to ('mean', 'AMT_DOWN_PAYMENT', 'XNA')\n",
      "dtypes: float16(48), float32(133), float64(51), int16(18), int32(8), int8(6), uint16(1), uint32(1), uint8(20)\n",
      "memory usage: 385.9 MB\n"
     ]
    }
   ],
   "source": [
    "iv_extended_feat_imp_feat = pd.read_csv(f'{file_path}leonid23(iv_ext)_fi_sorted.csv').iloc[:,0].tolist()\n",
    "iv_extended_feat = iv_extended_feat[['SK_ID_CURR'] + iv_extended_feat_imp_feat]\n",
    "iv_extended_feat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 356251 entries, 0 to 356254\n",
      "Columns: 721 entries, index to CC_COUNT\n",
      "dtypes: float16(289), float32(135), float64(139), int16(2), int8(1), uint32(2), uint8(153)\n",
      "memory usage: 816.8 MB\n",
      "Wall time: 55.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df4 = pd.read_pickle('../data/df.pkl.gz')\n",
    "# df4 = df4.join(pd.DataFrame(prev_paid), on='SK_ID_CURR')\n",
    "# df4['PAID'].fillna(0, inplace = True)\n",
    "df4 = gentle_reduce_mem_usage(df4, verbose = False)\n",
    "df4.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 356251 entries, 0 to 356254\n",
      "Columns: 495 entries, SK_ID_CURR to BURO_CREDIT_CURRENCY_currency 1_MEAN\n",
      "dtypes: float16(174), float32(114), float64(132), uint32(1), uint8(74)\n",
      "memory usage: 661.1 MB\n"
     ]
    }
   ],
   "source": [
    "df4_important_features = pd.read_csv(f'{file_path}leonid22_fi_sorted.csv').iloc[:,0].tolist()\n",
    "df4_important_features = [f for f in df4_important_features if f not in ['TARGET','SK_ID_BUREAU','SK_ID_PREV',\n",
    "                                                                 'index', 'PAID'] + iv_extended_feat_imp_feat]\n",
    "df4 = df4[['SK_ID_CURR'] + df4_important_features]\n",
    "df4.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 356255 entries, 0 to 356254\n",
      "Columns: 857 entries, SK_ID_CURR to CLOSED_DPD_1 / Month_MIN_STD\n",
      "dtypes: float16(462), float32(302), float64(27), uint32(1), uint8(65)\n",
      "memory usage: 821.2 MB\n",
      "Wall time: 9.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df3 = pd.read_pickle(f'{file_path}data_7_house_leak_paid.pkl.zip')\n",
    "df3_important_features = pd.read_csv(f'{file_path}leonid15_fi_sorted.csv').iloc[:,0].tolist()\n",
    "df3_important_features = [f for f in df3_important_features if f not in ['TARGET','SK_ID_BUREAU','SK_ID_PREV',\n",
    "                                                                 'index', 'PAID'] + iv_extended_feat_imp_feat\\\n",
    "                                                                  + df4.columns.tolist()]\n",
    "df3 = df3[['SK_ID_CURR', 'TARGET'] + df3_important_features]\n",
    "df3.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 356244 entries, 0 to 356254\n",
      "Data columns (total 44 columns):\n",
      "SK_ID_CURR                                                       356244 non-null uint32\n",
      "app AMT_INCOME_TOTAL / CNT_FAM_MEMBERS                           356244 non-null float32\n",
      "app DAYS_LAST_PHONE_CHANGE / DAYS_EMPLOYED                       356243 non-null float32\n",
      "CODE_GENDER_0                                                    356244 non-null uint8\n",
      "REGION_RATING_CLIENT_W_CITY_1                                    356244 non-null uint8\n",
      "BURO_DPD_0 / Month_MIN_MEAN                                      130695 non-null float64\n",
      "BURO_STATUS_1_MEAN_MIN                                           134542 non-null float16\n",
      "ACTIVE_DAYS_CREDIT_SIZE                                          251810 non-null float16\n",
      "PREV_AMT_ANNUITY_SIZE                                            338851 non-null float16\n",
      "PREV_NFLAG_INSURED_ON_APPROVAL_-inf_MEAN                         338851 non-null float16\n",
      "APPROVED_AMT_APPLICATION_SUM                                     337692 non-null float32\n",
      "APPROVED_AMT_CREDIT_SUM                                          337692 non-null float64\n",
      "APPROVED_AMT_GOODS_PRICE_MIN                                     336615 non-null float32\n",
      "APPROVED_RATE_DOWN_PAYMENT_VAR                                   173890 non-null float64\n",
      "APPROVED_prev AMT_APPLICATION / AMT_CREDIT_SUM                   337692 non-null float64\n",
      "APPROVED_prev AMT_GOODS_PRICE - AMT_CREDIT_MIN                   336615 non-null float64\n",
      "APPROVED_prev AMT_GOODS_PRICE - AMT_CREDIT_MAX                   336615 non-null float64\n",
      "APPROVED_prev AMT_GOODS_PRICE - AMT_CREDIT_MEAN                  336615 non-null float64\n",
      "APPROVED_prev AMT_GOODS_PRICE - AMT_CREDIT_SUM                   337692 non-null float64\n",
      "APPROVED_CHANNEL_TYPE_Stone_MEAN                                 337692 non-null float16\n",
      "APPROVED_PRODUCT_COMBINATION_Cash Street: high_MEAN              337692 non-null float16\n",
      "APPROVED_NAME_PRODUCT_TYPE_walk-in_MEAN                          337692 non-null float16\n",
      "APPROVED_NAME_YIELD_GROUP_low_action_MEAN                        337692 non-null float16\n",
      "REFUSED_AMT_ANNUITY_SIZE                                         118272 non-null float16\n",
      "REFUSED_AMT_CREDIT_VAR                                           63657 non-null float64\n",
      "REFUSED_AMT_GOODS_PRICE_MIN                                      110037 non-null float32\n",
      "REFUSED_DAYS_DECISION_MIN                                        118272 non-null float32\n",
      "REFUSED_DAYS_DECISION_VAR                                        63657 non-null float64\n",
      "REFUSED_SELLERPLACE_AREA_MEAN                                    118272 non-null float32\n",
      "REFUSED_prev missing_VAR                                         63657 non-null float64\n",
      "REFUSED_prev missing_SUM                                         118272 non-null float16\n",
      "REFUSED_prev AMT_APPLICATION / AMT_CREDIT_MIN                    112451 non-null float64\n",
      "REFUSED_prev AMT_APPLICATION / AMT_CREDIT_MAX                    112451 non-null float64\n",
      "REFUSED_prev AMT_APPLICATION / AMT_CREDIT_MEAN                   112451 non-null float64\n",
      "REFUSED_prev AMT_APPLICATION - AMT_CREDIT_SUM                    118272 non-null float64\n",
      "REFUSED_prev AMT_GOODS_PRICE - AMT_CREDIT_MIN                    110036 non-null float64\n",
      "REFUSED_prev AMT_GOODS_PRICE - AMT_CREDIT_VAR                    56571 non-null float64\n",
      "REFUSED_PRODUCT_COMBINATION_Cash X-Sell: high_MEAN               118272 non-null float16\n",
      "REFUSED_PRODUCT_COMBINATION_Cash_MEAN                            118272 non-null float16\n",
      "REFUSED_PRODUCT_COMBINATION_Cash Street: middle_MEAN             118272 non-null float16\n",
      "REFUSED_NAME_YIELD_GROUP_XNA_MEAN                                118272 non-null float16\n",
      "CARD_AMT_PAYMENT_CURRENT_VAR                                     71602 non-null float32\n",
      "CARD_card AMT_TOTAL_RECEIVABLE - AMT_RECEIVABLE_PRINCIPAL_VAR    102865 non-null float64\n",
      "CARD_card AMT_BALANCE - AMT_RECIVABLE_VAR                        102865 non-null float64\n",
      "dtypes: float16(14), float32(8), float64(19), uint32(1), uint8(2)\n",
      "memory usage: 76.8 MB\n",
      "Wall time: 4.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df2 = pd.read_pickle(f'{file_path}aggregated_df2_boostarooted314.pkl.zip')\n",
    "df2_important_features = [f for f in df2.columns.tolist() if f not in ['TARGET','SK_ID_BUREAU','SK_ID_PREV',\n",
    "                                                                 'index', 'PAID'] + iv_extended_feat_imp_feat\\\n",
    "                                                                  + df4.columns.tolist() + df3.columns.tolist()]\n",
    "df2 = df2[['SK_ID_CURR'] + df2_important_features]\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 356255 entries, 0 to 356254\n",
      "Columns: 1679 entries, SK_ID_CURR to CARD_card AMT_BALANCE - AMT_RECIVABLE_VAR\n",
      "dtypes: float16(698), float32(557), float64(358), uint32(1), uint8(65)\n",
      "memory usage: 2.2 GB\n",
      "Wall time: 5min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_extended = df3.merge(iv_extended_feat, on='SK_ID_CURR', how='left')\n",
    "df_extended = df_extended.merge(df4, on='SK_ID_CURR', how='left')\n",
    "df_extended = df_extended.merge(df2, on='SK_ID_CURR', how='left')\n",
    "df_extended.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48744, 1679)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_extended[df_extended['TARGET'].isnull()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strong_features = pd.read_csv(f'{file_path}leonid24(df_ext01)_fi_strong.csv').iloc[:,0].tolist()\n",
    "len(strong_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 356255 entries, 0 to 356254\n",
      "Columns: 502 entries, SK_ID_CURR to ACTIVE_DAYS_CREDIT_ENDDATE_SUM\n",
      "dtypes: float16(182), float32(230), float64(89), uint32(1)\n",
      "memory usage: 682.2 MB\n",
      "Wall time: 48.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_extended = df_extended[['SK_ID_CURR', 'TARGET'] + strong_features]\n",
    "df_extended = gentle_reduce_mem_usage(df_extended, verbose = False)\n",
    "df_extended.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 23.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df2 = pd.read_pickle(f'{file_path}aggregated_df2_boostarooted314.pkl.zip')\n",
    "df3 = pd.read_pickle(f'{file_path}data_7_house_leak_paid.pkl.zip')\n",
    "df4 = pd.read_pickle('../data/df.pkl.gz')\n",
    "iv_extended_feat = pd.read_pickle(f'{file_path}iv_extended_feat.pkl.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_features = df2.columns.tolist() + df3.columns.tolist() + df4.columns.tolist()\\\n",
    "                    + iv_extended_feat.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2619"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processed_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df2, df3, df4, iv_extended_feat\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 27.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "aggregated_df2 = pd.read_pickle(f'{file_path}aggregated_df2.pkl.zip')\n",
    "processed_features = list(set(processed_features) | set(aggregated_df2.columns))\n",
    "del aggregated_df2\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4241"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processed_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 356244 entries, 0 to 356243\n",
      "Columns: 758 entries, AMT_ANNUITY to CARD_SK_DPD_SUM\n",
      "dtypes: float64(734), int64(24)\n",
      "memory usage: 2.0 GB\n",
      "Wall time: 51.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tearth_cat6 = pd.read_csv('../features/tEarth_cat6.csv')\n",
    "tearth_cat6.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 500 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# tearth_cat6_imp_f = [f for f in tearth_cat6.columns.tolist() if f not in ['TARGET','SK_ID_BUREAU','SK_ID_PREV',\n",
    "#                                                                  'index', 'PAID'] + processed_features + USELESS_COLUMNS\\\n",
    "#                                                              + [x for x in tearth_cat6.columns.tolist() if 'SK_ID_'  in x]  ]\n",
    "processed_features = list(set(processed_features) | set(tearth_cat6.columns.tolist()))\n",
    "# tearth_cat6 = tearth_cat6[['SK_ID_CURR'] + tearth_cat6_imp_f]\n",
    "# tearth_cat6 = gentle_reduce_mem_usage(tearth_cat6, verbose = False)\n",
    "# tearth_cat6.to_pickle(f'{file_path}tearth_cat6.pkl.zip')\n",
    "# tearth_cat6.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 356244 entries, 0 to 356243\n",
      "Data columns (total 12 columns):\n",
      "SK_ID_CURR    356244 non-null int64\n",
      "pca_col_0     356244 non-null float64\n",
      "pca_col_1     356244 non-null float64\n",
      "pca_col_2     356244 non-null float64\n",
      "pca_col_3     356244 non-null float64\n",
      "pca_col_4     356244 non-null float64\n",
      "pca_col_5     356244 non-null float64\n",
      "pca_col_6     356244 non-null float64\n",
      "pca_col_7     356244 non-null float64\n",
      "pca_col_8     356244 non-null float64\n",
      "pca_col_9     356244 non-null float64\n",
      "cluster       356244 non-null int64\n",
      "dtypes: float64(10), int64(2)\n",
      "memory usage: 32.6 MB\n",
      "Wall time: 2.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pca_cluster = pd.concat([pd.read_csv(f'{file_path}pca+cluster/iv_train_stack_feat.csv'),\n",
    "                      pd.read_csv(f'{file_path}pca+cluster/iv_test_stack_feat.csv')], ignore_index=True,\n",
    "                     axis=0, verify_integrity=True)\n",
    "processed_features = list(set(processed_features) | set(pca_cluster.columns.tolist()))\n",
    "pca_cluster.to_pickle(f'{file_path}iv_pca_cluster.pkl.zip')\n",
    "pca_cluster.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "iv_extended_v2_feat_train = pd.read_csv(f'{file_path}iv ext feat v.2/iv_train_383feat.csv')\n",
    "iv_extended_v2_feat_target = pd.read_csv(f'{file_path}iv ext feat v.2/iv_target.csv',\n",
    "                      header = None, names = ['SK_ID_CURR', 'TARGET'])\n",
    "iv_extended_v2_feat_test = pd.read_csv(f'{file_path}iv ext feat v.2/iv_test_383feat.csv')\n",
    "iv_extended_v2_feat_train = iv_extended_v2_feat_train.merge(iv_extended_v2_feat_target,\n",
    "                                                     on='SK_ID_CURR')\n",
    "iv_extended_v2_feat = pd.concat([iv_extended_v2_feat_train, iv_extended_v2_feat_test],\n",
    "                             ignore_index = True, axis=0, verify_integrity = True)\n",
    "# iv_extended_v2_feat = gentle_reduce_mem_usage(iv_extended_v2_feat, verbose = False)\n",
    "del iv_extended_v2_feat_train, iv_extended_v2_feat_target, iv_extended_v2_feat_test\n",
    "gc.collect()\n",
    "# iv_extended_v2_feat.to_pickle(f'{file_path}iv_extended_v2_feat_full.pkl.zip')\n",
    "# iv_extended_v2_feat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iv_extended_v2_imp_f = [f for f in iv_extended_v2_feat.columns.tolist() if f not in ['TARGET','SK_ID_BUREAU','SK_ID_PREV',\n",
    "#                                                                  'index', 'PAID'] + processed_features + USELESS_COLUMNS\\\n",
    "#                                                       + [x for x in iv_extended_v2_feat.columns.tolist() if 'SK_ID_'  in x]  ]\n",
    "processed_features = list(set(processed_features) | set(iv_extended_v2_feat.columns.tolist()))\n",
    "# iv_extended_v2_feat = iv_extended_v2_feat[['SK_ID_CURR'] + iv_extended_v2_imp_f]\n",
    "# len(iv_extended_v2_imp_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'processed_features': processed_features}).to_pickle(f'{file_path}processed_features_v2.pkl.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_features = pd.read_pickle(f'{file_path}processed_features_v2.pkl.zip')['processed_features'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 356255 entries, 0 to 356254\n",
      "Columns: 667 entries, SK_ID_CURR to nrm_app most popular AMT_GOODS_PRICE\n",
      "dtypes: float16(222), float32(255), float64(189), uint32(1)\n",
      "memory usage: 1015.2 MB\n",
      "Wall time: 1min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_extended = df_extended.merge(tearth_cat6, on='SK_ID_CURR', how='left')\n",
    "df_extended = df_extended.merge(pca_cluster, on='SK_ID_CURR', how='left')\n",
    "df_extended = df_extended.merge(iv_extended_v2_feat, on='SK_ID_CURR', how='left')\n",
    "df_extended.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_ext = [x for x in df_extended.columns.tolist() if 'EXT_SOURCE'  in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 356255 entries, 0 to 356254\n",
      "Columns: 640 entries, SK_ID_CURR to nrm_app most popular AMT_GOODS_PRICE\n",
      "dtypes: float16(210), float32(253), float64(176), uint32(1)\n",
      "memory usage: 969.0 MB\n"
     ]
    }
   ],
   "source": [
    "df_extended.drop(remove_ext, axis=1, inplace=True)\n",
    "df_extended.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48744, 640)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_extended[df_extended['TARGET'].isnull()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 356255 entries, 0 to 356254\n",
      "Columns: 640 entries, SK_ID_CURR to nrm_app most popular AMT_GOODS_PRICE\n",
      "dtypes: float16(215), float32(253), float64(171), uint32(1)\n",
      "memory usage: 958.8 MB\n"
     ]
    }
   ],
   "source": [
    "df_extended = gentle_reduce_mem_usage(df_extended, verbose = False)\n",
    "df_extended.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extended.to_pickle(f'{file_path}df_extended_v2.pkl.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 356251 entries, 0 to 356250\n",
      "Columns: 1537 entries, SK_ID_CURR to 1535\n",
      "dtypes: float64(1536), int64(1)\n",
      "memory usage: 4.1 GB\n",
      "Wall time: 5.92 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gp123 = pd.read_pickle(f'{file_path}gp123.pkl')\n",
    "gp123.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extended.to_pickle(f'{file_path}df_extended.pkl.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_extended = pd.read_pickle(f'{file_path}df_extended.pkl.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extended2 = df_extended.join(pd.DataFrame(prev_paid), on='SK_ID_CURR')\n",
    "df_extended2['PAID'].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
